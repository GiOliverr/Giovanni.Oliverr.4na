{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d1a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc96ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_texto(texto):\n",
    "    texto = texto.lower()  # Converte tudo para minúsculas\n",
    "    texto = re.sub(r'[^\\w\\s]', ' ', texto)  # Remove pontuações\n",
    "    texto = re.sub(r'\\d+', ' ', texto)      # Remove números\n",
    "    texto = re.sub(r'\\s+', ' ', texto)      # Substitui múltiplos espaços por um só\n",
    "    return texto.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b95643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_demo = \"\"\"\n",
    "A modelagem de linguagens é uma área da linguística computacional e da inteligência artificial que tem como objetivo representar, \n",
    "processar e gerar textos em linguagem humana de forma automática. Modelos de linguagem são algoritmos que aprendem padrões estatísticos \n",
    "a partir de grandes corpora (coleções de textos) para prever a próxima palavra de uma sentença ou avaliar a probabilidade de uma sequência de palavras.\n",
    "Existem diferentes tipos de modelos de linguagem, sendo os **n-gramas** os mais simples e tradicionais. Um modelo de n-grama utiliza a frequência com que\n",
    "sequências de *n* palavras ocorrem em um corpus para estimar probabilidades. Por exemplo, um **modelo unigram** considera apenas a frequência individual\n",
    "das palavras; um **bigram** leva em conta pares de palavras consecutivas; e um **trigram** analisa trios de palavras.\n",
    "Apesar da simplicidade, esses modelos são bastante eficazes em tarefas como correção ortográfica, sugestão de palavras, tradução automática e sistemas de \n",
    "reconhecimento de fala. No entanto, apresentam limitações quanto à captura de dependências de longo alcance, o que motivou o desenvolvimento de modelos mais \n",
    "avançados baseados em redes neurais, como os modelos RNN, LSTM, e os atuais **transformers**, utilizados em sistemas como o ChatGPT.\n",
    "A modelagem de linguagens é fundamental para a criação de tecnologias mais acessíveis, inteligentes e capazes de interagir de forma natural com os seres humanos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621c15ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a modelagem de linguagem natural é uma técnica importante no processamento de linguagem natural os modelos de linguagem podem ser usados para prever a próxima palavra em uma sequência existem diversos tipos de modelos de linguagem incluindo modelos baseados em n grams e modelos neurais os modelos baseados em n grams são mais simples mas ainda muito úteis em diversas aplicações\n"
     ]
    }
   ],
   "source": [
    "texto_tratado = limpar_texto(texto_demo)\n",
    "print(texto_tratado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0436cad3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m palavras = \u001b[43mlimpar_texto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexto_demo\u001b[49m\u001b[43m)\u001b[49m.split()\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuantidade de palavras:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(palavras))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExemplo:\u001b[39m\u001b[33m\"\u001b[39m, palavras[:\u001b[32m50\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mlimpar_texto\u001b[39m\u001b[34m(texto)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlimpar_texto\u001b[39m(texto):\n\u001b[32m      2\u001b[39m     texto = texto.lower()  \u001b[38;5;66;03m# Converte tudo para minúsculas\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     texto = \u001b[43mre\u001b[49m.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[^\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m, texto)  \u001b[38;5;66;03m# Remove pontuações\u001b[39;00m\n\u001b[32m      4\u001b[39m     texto = re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m, texto)      \u001b[38;5;66;03m# Remove números\u001b[39;00m\n\u001b[32m      5\u001b[39m     texto = re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m, texto)      \u001b[38;5;66;03m# Substitui múltiplos espaços por um só\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "palavras = limpar_texto(texto_demo).split()\n",
    "print(\"Quantidade de palavras:\", len(palavras))\n",
    "print(\"Exemplo:\", palavras[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c178f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeloNGram:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.contagens = defaultdict(Counter)\n",
    "        self.modelo = {}\n",
    "\n",
    "    def treinar(self, palavras):\n",
    "        for i in range(len(palavras) - self.n + 1):\n",
    "            contexto = tuple(palavras[i:i+self.n-1])\n",
    "            alvo = palavras[i+self.n-1]\n",
    "            self.contagens[contexto][alvo] += 1\n",
    "\n",
    "        for contexto, alvos in self.contagens.items():\n",
    "            total = sum(alvos.values())\n",
    "            self.modelo[contexto] = {\n",
    "                palavra: freq / total for palavra, freq in alvos.items()\n",
    "            }\n",
    "\n",
    "    def proxima_palavra(self, contexto):\n",
    "        contexto = tuple(contexto[-(self.n-1):]) if self.n > 1 else ()\n",
    "        if contexto in self.modelo:\n",
    "            palavras = list(self.modelo[contexto].keys())\n",
    "            probs = list(self.modelo[contexto].values())\n",
    "            return np.random.choice(palavras, p=probs)\n",
    "        return None\n",
    "\n",
    "    def gerar_texto(self, contexto_inicial, quantidade=15):\n",
    "        if isinstance(contexto_inicial, str):\n",
    "            contexto_inicial = contexto_inicial.split()\n",
    "        if len(contexto_inicial) < self.n - 1:\n",
    "            raise ValueError(f\"Contexto inicial deve ter pelo menos {self.n - 1} palavras\")\n",
    "        texto = list(contexto_inicial)\n",
    "        for _ in range(quantidade):\n",
    "            prox = self.proxima_palavra(texto)\n",
    "            if not prox:\n",
    "                break\n",
    "            texto.append(prox)\n",
    "        return ' '.join(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ee8a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_1gram = ModeloNGram(1)\n",
    "modelo_2gram = ModeloNGram(2)\n",
    "modelo_3gram = ModeloNGram(3)\n",
    "modelo_7gram = ModeloNGram(7)\n",
    "\n",
    "modelo_1gram.treinar(palavras)\n",
    "modelo_2gram.treinar(palavras)\n",
    "modelo_3gram.treinar(palavras)\n",
    "modelo_7gram.treinar(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18be32da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexidade:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'modelo_1gram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     13\u001b[39m texto_teste = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33mA modelagem de linguagens é uma área da linguística computacional e da inteligência artificial que tem como objetivo representar, \u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33mprocessar e gerar textos em linguagem humana de forma automática. Modelos de linguagem são algoritmos que aprendem padrões estatísticos \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[33mA modelagem de linguagens é fundamental para a criação de tecnologias mais acessíveis, inteligentes e capazes de interagir de forma natural com os seres humanos.\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPerplexidade:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUnigram:\u001b[39m\u001b[33m\"\u001b[39m, calcular_perplexidade(\u001b[43mmodelo_1gram\u001b[49m, texto_teste))\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBigram:\u001b[39m\u001b[33m\"\u001b[39m, calcular_perplexidade(modelo_2gram, texto_teste))\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrigram:\u001b[39m\u001b[33m\"\u001b[39m, calcular_perplexidade(modelo_3gram, texto_teste))\n",
      "\u001b[31mNameError\u001b[39m: name 'modelo_1gram' is not defined"
     ]
    }
   ],
   "source": [
    "def calcular_perplexidade(modelo, texto_teste):\n",
    "    tokens = limpar_texto(texto_teste).split()\n",
    "    log_prob = 0\n",
    "    total = 0\n",
    "    for i in range(modelo.n - 1, len(tokens)):\n",
    "        contexto = tuple(tokens[i - modelo.n + 1:i]) if modelo.n > 1 else ()\n",
    "        alvo = tokens[i]\n",
    "        prob = modelo.modelo.get(contexto, {}).get(alvo, 1e-10)\n",
    "        log_prob += np.log2(prob)\n",
    "        total += 1\n",
    "    return 2 ** (-log_prob / total) if total > 0 else float('inf')\n",
    "\n",
    "texto_teste = \"\"\"\n",
    "A modelagem de linguagens é uma área da linguística computacional e da inteligência artificial que tem como objetivo representar, \n",
    "processar e gerar textos em linguagem humana de forma automática. Modelos de linguagem são algoritmos que aprendem padrões estatísticos \n",
    "a partir de grandes corpora (coleções de textos) para prever a próxima palavra de uma sentença ou avaliar a probabilidade de uma sequência de palavras.\n",
    "Existem diferentes tipos de modelos de linguagem, sendo os **n-gramas** os mais simples e tradicionais. Um modelo de n-grama utiliza a frequência com que\n",
    "sequências de *n* palavras ocorrem em um corpus para estimar probabilidades. Por exemplo, um **modelo unigram** considera apenas a frequência individual\n",
    "das palavras; um **bigram** leva em conta pares de palavras consecutivas; e um **trigram** analisa trios de palavras.\n",
    "Apesar da simplicidade, esses modelos são bastante eficazes em tarefas como correção ortográfica, sugestão de palavras, tradução automática e sistemas de \n",
    "reconhecimento de fala. No entanto, apresentam limitações quanto à captura de dependências de longo alcance, o que motivou o desenvolvimento de modelos mais \n",
    "avançados baseados em redes neurais, como os modelos RNN, LSTM, e os atuais **transformers**, utilizados em sistemas como o ChatGPT.\n",
    "A modelagem de linguagens é fundamental para a criação de tecnologias mais acessíveis, inteligentes e capazes de interagir de forma natural com os seres humanos.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Perplexidade:\")\n",
    "print(\"Unigram:\", calcular_perplexidade(modelo_1gram, texto_teste))\n",
    "print(\"Bigram:\", calcular_perplexidade(modelo_2gram, texto_teste))\n",
    "print(\"Trigram:\", calcular_perplexidade(modelo_3gram, texto_teste))\n",
    "print(\"setagram:\", calcular_perplexidade(modelo_7gram, texto_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c0de70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelo_1gram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     plt.xticks(rotation=\u001b[32m45\u001b[39m)\n\u001b[32m     14\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m mostrar_distribuicao(\u001b[43mmodelo_1gram\u001b[49m)\n\u001b[32m     17\u001b[39m mostrar_distribuicao(modelo_2gram)\n\u001b[32m     18\u001b[39m mostrar_distribuicao(modelo_7gram)\n",
      "\u001b[31mNameError\u001b[39m: name 'modelo_1gram' is not defined"
     ]
    }
   ],
   "source": [
    "def mostrar_distribuicao(modelo, contexto=None):\n",
    "    if modelo.n == 1:\n",
    "        contexto = ()\n",
    "    if contexto is None or contexto not in modelo.modelo:\n",
    "        contexto = list(modelo.modelo.keys())[0]\n",
    "    palavras = list(modelo.modelo[contexto].keys())\n",
    "    probs = list(modelo.modelo[contexto].values())\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(palavras[:10], probs[:10])\n",
    "    titulo = \"Distribuição unigram\" if modelo.n == 1 else f\"Contexto: {' '.join(contexto)}\"\n",
    "    plt.title(titulo)\n",
    "    plt.ylabel(\"Probabilidade\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "mostrar_distribuicao(modelo_1gram)\n",
    "mostrar_distribuicao(modelo_2gram)\n",
    "mostrar_distribuicao(modelo_7gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46031477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia_edicao(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return distancia_edicao(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    anterior = list(range(len(s2) + 1))\n",
    "    for i, c1 in enumerate(s1):\n",
    "        atual = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            custos = [\n",
    "                anterior[j + 1] + 1,\n",
    "                atual[j] + 1,\n",
    "                anterior[j] + (c1 != c2)\n",
    "            ]\n",
    "            atual.append(min(custos))\n",
    "        anterior = atual\n",
    "    return anterior[-1]\n",
    "\n",
    "def sugerir_palavra(palavra, modelo):\n",
    "    if palavra in modelo.modelo[()]:\n",
    "        return palavra\n",
    "    candidatos = []\n",
    "    for voc in modelo.modelo[()]:\n",
    "        dist = distancia_edicao(palavra, voc)\n",
    "        if dist <= 2:\n",
    "            prob = modelo.modelo[()].get(voc, 0)\n",
    "            candidatos.append((voc, dist, prob))\n",
    "    if not candidatos:\n",
    "        return palavra\n",
    "    candidatos.sort(key=lambda x: (x[1], -x[2]))\n",
    "    return candidatos[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8add4742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correções sugeridas:\n",
      "modelgem → modelgem\n",
      "linguaem → linguagem\n",
      "natual → natual\n",
      "processment → processment\n"
     ]
    }
   ],
   "source": [
    "palavras_erradas = [\"modelgem\", \"linguaem\", \"natual\", \"processment\"]\n",
    "print(\"Correções sugeridas:\")\n",
    "for erro in palavras_erradas:\n",
    "    print(f\"{erro} → {sugerir_palavra(erro, modelo_1gram)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82f37c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textos gerados:\n",
      "Unigram: um tipos de trios trios a de grama modelo existem que bigram que linguagem n modelo diferentes tradicionais trigram um n de estimar apenas a mais apenas tradicionais estimar ocorrem\n",
      "Bigram: existem diferentes tipos de palavras um modelo de palavras ocorrem em conta pares de n grama\n",
      "Trigram: diferentes tipos de modelos de linguagem sendo os n gramas os mais simples e tradicionais um modelo de n palavras ocorrem em um corpus para estimar probabilidades por exemplo um modelo unigram considera apenas a frequência individual das palavras um bigram leva em conta pares de palavras consecutivas e um trigram analisa\n",
      "setagram: de modelos de linguagem sendo os n gramas os mais simples e tradicionais um modelo de n grama utiliza a frequência com que sequências de n palavras ocorrem em um corpus para estimar probabilidades por exemplo um modelo unigram considera apenas a frequência individual das palavras um bigram leva em conta pares de palavras consecutivas e um trigram analisa trios de palavras\n"
     ]
    }
   ],
   "source": [
    "print(\"Textos gerados:\")\n",
    "print(\"Unigram:\", modelo_1gram.gerar_texto([], 30))\n",
    "print(\"Bigram:\", modelo_2gram.gerar_texto([\"existem\"], 15))\n",
    "print(\"Trigram:\", modelo_3gram.gerar_texto([\"diferentes\", \"tipos\"], 50))\n",
    "print(\"setagram:\", modelo_7gram.gerar_texto([\"de\", \"modelos\",'de', 'linguagem', 'sendo', 'os', 'n', 'gramas'], 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
